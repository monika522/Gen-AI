{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUE-rF9YLrsW",
        "outputId": "bcc7b2a3-98bd-4d80-ac01-0d82e8286d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python==0.2.69 in /usr/local/lib/python3.10/dist-packages (0.2.69)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.69) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.69) (1.26.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.69) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.69) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.69) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain>=0.1.17 openai>=1.13.3 langchain_openai>=0.1.6 transformers>=4.40.1 datasets>=2.18.0 accelerate>=0.27.2 sentence-transformers>=2.5.1 duckduckgo-search>=5.2.2 langchain_community\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.69"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Tx2FHvbR80O",
        "outputId": "e4ea25c0-f5f6-4345-942d-219fd061c7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-11 03:37:51--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.55, 18.164.174.118, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1731555471&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTU1NTQ3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=TMFIpN%7EK5EbszYiXiYKr2qAsl9Pn1RJo-D6azuOhTH%7EGwOFfruyrNnYXcDTQyIS9jIgtAgkyebq7HLl5MsOyM4FA1jv-N2k1Fu6iahVWgMdp6zxQwAI8iT%7E2penk11XN5-amuCALfJP7-diYDxk7CKXtoRAen7%7Ej8G5YcnSR9CEvquyxDr-afOyv4DfOCVq-FVWLxWxcGHcFpoGG6wOtbfAfjMnm2jOCkqnZIUfUM56Glv8nn%7ETAWIkEKrAdpMVg-sA7GXWewaxjyNEZIPNXsxAowxq4iJBzmaqN0zVFRRcu4dxFC0739-p2fcXbNJgT6od9ogX5BDbbXw5RHMct5A__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
            "--2024-11-11 03:37:51--  https://cdn-lfs-us-1.hf.co/repos/41/c8/41c860f65b01de5dc4c68b00d84cead799d3e7c48e38ee749f4c6057776e2e9e/5d99003e395775659b0dde3f941d88ff378b2837a8dc3a2ea94222ab1420fad3?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&Expires=1731555471&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTczMTU1NTQ3MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzQxL2M4LzQxYzg2MGY2NWIwMWRlNWRjNGM2OGIwMGQ4NGNlYWQ3OTlkM2U3YzQ4ZTM4ZWU3NDlmNGM2MDU3Nzc2ZTJlOWUvNWQ5OTAwM2UzOTU3NzU2NTliMGRkZTNmOTQxZDg4ZmYzNzhiMjgzN2E4ZGMzYTJlYTk0MjIyYWIxNDIwZmFkMz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=TMFIpN%7EK5EbszYiXiYKr2qAsl9Pn1RJo-D6azuOhTH%7EGwOFfruyrNnYXcDTQyIS9jIgtAgkyebq7HLl5MsOyM4FA1jv-N2k1Fu6iahVWgMdp6zxQwAI8iT%7E2penk11XN5-amuCALfJP7-diYDxk7CKXtoRAen7%7Ej8G5YcnSR9CEvquyxDr-afOyv4DfOCVq-FVWLxWxcGHcFpoGG6wOtbfAfjMnm2jOCkqnZIUfUM56Glv8nn%7ETAWIkEKrAdpMVg-sA7GXWewaxjyNEZIPNXsxAowxq4iJBzmaqN0zVFRRcu4dxFC0739-p2fcXbNJgT6od9ogX5BDbbXw5RHMct5A__&Key-Pair-Id=K24J24Z295AEI9\n",
            "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.164.174.52, 18.164.174.19, 18.164.174.98, ...\n",
            "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.164.174.52|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7643295904 (7.1G) [binary/octet-stream]\n",
            "Saving to: ‘Phi-3-mini-4k-instruct-fp16.gguf’\n",
            "\n",
            "Phi-3-mini-4k-instr 100%[===================>]   7.12G  42.3MB/s    in 3m 2s   \n",
            "\n",
            "2024-11-11 03:40:53 (40.1 MB/s) - ‘Phi-3-mini-4k-instruct-fp16.gguf’ saved [7643295904/7643295904]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LlamaCpp\n",
        "\n",
        "#Make sure the model path is correct for your\n",
        "llm=LlamaCpp(\n",
        "    model_path=\"Phi-3-mini-4k-instruct-fp16.gguf\",\n",
        "    n_gup_layers=-1,\n",
        "    max_tokens=500,\n",
        "    n_ctx=2048,\n",
        "    seed=42,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "db6RLhG6TjZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"The quick brown fox jumps over the lazy\"\n",
        "#completion=llm(prompt)"
      ],
      "metadata": {
        "id": "9llSmdgtVFvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=llm(\n",
        "    f\"<|user|>\\n{prompt}<|end|>\\n<|assistant|>\",\n",
        "    max_tokens=256,\n",
        "    stop={\"<|end|>\"},\n",
        "    echo=True\n",
        ")\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US9G0wYpVq0e",
        "outputId": "dbc5bebe-5bcd-4190-ac3f-cffdfe45e7bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The quick brown fox jumps over the lazy dog. This sentence is a well-known pangram, which means it contains every letter of the English alphabet at least once. Pangrams are commonly used for practicing typing, testing typewriters and computer keyboards, displaying font faces, and other applications where brevity combined with completeness is useful. In typography and design, sentences like this one help to evaluate how well a font renders each character in various combinations of letters, numbers, and punctuation marks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OUTPUT_parsing new book"
      ],
      "metadata": {
        "id": "G9fRdWccbjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a prompt template\n",
        "\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "template = \"\"\"<s><|user|>\n",
        "{input_prompt}<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    template=template,\n",
        "    input_variables=[\"input_prompt\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "qYXkkTxWZWSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain=prompt | llm"
      ],
      "metadata": {
        "id": "vRleI3CIah2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#use the chain\n",
        "basic_chain.invoke(\n",
        "    {\n",
        "        \"input_prompt\":\"Hi! My equqtion is XYZ.What is 2*5?\",\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nOMhTqbYamED",
        "outputId": "97b2f625-3f42-4756-be4e-925ab56f17ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The equation you provided, \"XYZ,\" does not directly relate to the arithmetic operation in question. However, if we focus on your mathematical query: 2 multiplied by 5 equals 10. So, 2 * 5 = 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple chains"
      ],
      "metadata": {
        "id": "gTeV8awWcARe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain\n",
        "\n",
        "#Create a chain for the title of ur story\n",
        "template=\"\"\"<s><|user|>\n",
        "Create a title for a story about {summary}.Only return the title.<|end|>\n",
        "<|assistant|>\"\"\"\n",
        "title_prompt=PromptTemplate(template=template, input_variables=[\"summary\"])\n",
        "title=LLMChain(llm=llm, prompt=title_prompt, output_key=\"title\")"
      ],
      "metadata": {
        "id": "JvOCZfXecDF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title.invoke({\"summary\":\"a girl got magical shoes\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2oHnqg7c2Mc",
        "outputId": "762b68c7-fd80-4bf4-ba94-40bae0c89d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'summary': 'a girl got magical shoes',\n",
              " 'title': ' \"Enchanted Steps: The Tale of the Magical Shoes\"'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}